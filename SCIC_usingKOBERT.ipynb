{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCIC_usingKOBERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a52a5f1de034504ae71cd70fee438c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1033d9ebb9c4c72888305701694a818",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dbade7ee2d7a49c294260212263a0f65",
              "IPY_MODEL_464bffeca49644c9a8f1a5216842eeac"
            ]
          }
        },
        "b1033d9ebb9c4c72888305701694a818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbade7ee2d7a49c294260212263a0f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e615b235a74d454890d6c7d28d16cdf7",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 750,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04f15c834ee94665bc04beefb830505e"
          }
        },
        "464bffeca49644c9a8f1a5216842eeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c33c2a980eff4927ba1f74c6867b6817",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/750 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6b0fc725ac04ec18fda27e2c852440f"
          }
        },
        "e615b235a74d454890d6c7d28d16cdf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04f15c834ee94665bc04beefb830505e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c33c2a980eff4927ba1f74c6867b6817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6b0fc725ac04ec18fda27e2c852440f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sy7cduyPuKc",
        "outputId": "6a170399-3071-41ae-8432-ad69a2fd234a"
      },
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3.0.2\n",
        "!pip install torch\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 40 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595719 sha256=06eb50641df23b704e89d1501b24064e8dbe05aea7ee0cb0b7f9dcb9652052e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 35.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 37.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 67.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-6f_94igu\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-6f_94igu\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12770 sha256=e2d10c7cfed3366c4dc6e43e6da4c07c834308a35df2aee86b9e487c36070292\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xmdzb08n/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViS_9Qe5bJ47",
        "outputId": "7231ffe0-7cf1-42d1-b5fe-56bc378ed98e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 띄어쓰기\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "\n",
        "# 맞춤법\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-wcfl5w2p\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-wcfl5w2p\n",
            "Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.5) (2.5.0)\n",
            "Requirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.5) (3.1.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.5.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.2.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.34.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (2.5.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0->pykospacing==0.5) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (57.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.32.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.4.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->pykospacing==0.5) (3.5.0)\n",
            "Building wheels for collected packages: pykospacing\n",
            "  Building wheel for pykospacing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykospacing: filename=pykospacing-0.5-py3-none-any.whl size=2255828 sha256=195b424657e69cb344a0f9bc3f7278c49c5ab32b2cf5c6ffddeda57d78f29762\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-revui114/wheels/9b/93/81/a2a7dc8c66ede5bf30634d20635f32b95eac7ca2ea8844058b\n",
            "Successfully built pykospacing\n",
            "Installing collected packages: argparse, pykospacing\n",
            "Successfully installed argparse-1.4.0 pykospacing-0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-gsd3dev0\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-gsd3dev0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4870 sha256=7ef348998742283fc5d52dd67e57b0965f15a38a2e3cdca88d9ad7f8339c84fb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-44ox88_n/wheels/ab/f5/7b/d4124bb329c905301baed80e2ae45aa14e824f62ebc3ec2cc4\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p71nEKXWQCRG"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "#kobert\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "#transformers\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QeJ5PuLQRAD",
        "outputId": "741e4440-b4d7-4665-8c46-0e4d0bb116a7"
      },
      "source": [
        "#GPU 사용\n",
        "device = torch.device(\"cuda:0\")\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsOnuaPmQR3w",
        "outputId": "11ccf71d-6dea-4b4e-e940-101c16f2473a"
      },
      "source": [
        "#BERT 모델, Vocabulary 불러오기\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f1s1jwBQXHd"
      },
      "source": [
        "data=pd.read_excel('/content/공모전_제공_데이터(1차).xlsx')\n",
        "classification=pd.read_excel('/content/공모전_제공_데이터(1차).xlsx', sheet_name='우선순위')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOBdgfMUWKFg",
        "outputId": "60e8610a-9ddb-4fd7-970e-01513163deaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 구두점 제거\n",
        "print(\"구두점 제거\")\n",
        "only_word = []\n",
        "for i in tqdm(range(len(data))):\n",
        "  tmp = re.compile('[^가-힣a-zA-Z0-9 | ㄱ-ㅎ | ㅏ-ㅣ]').sub(\"\",data.loc[i,'발화'])\n",
        "  only_word.append(tmp)\n",
        "\n",
        "# 띄어쓰기 제거\n",
        "print(\"띄어쓰기 제거\")\n",
        "no_space = []\n",
        "for i in tqdm(range(len(data))):\n",
        "  tmp = re.sub(r\"\\s+\", \"\", only_word[i])\n",
        "  no_space.append(tmp)\n",
        "\n",
        "# 띄어쓰기\n",
        "from pykospacing import Spacing\n",
        "print(\"띄어쓰기\")\n",
        "spc_data = []\n",
        "for i in tqdm(range(len(data))):\n",
        "  spacing = Spacing()\n",
        "  tmp = spacing(no_space[i]) \n",
        "  spc_data.append(tmp)\n",
        "\n",
        "# 맞춤법 교정\n",
        "from hanspell import spell_checker\n",
        "print(\"맞춤법교정\")\n",
        "spell_data = []\n",
        "for i in tqdm(range(len(data))):\n",
        "  tmp = spell_checker.check(spc_data[i])\n",
        "  hanspell_tmp = tmp.checked\n",
        "  spell_data.append(hanspell_tmp)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 56193.03it/s]\n",
            "100%|██████████| 1000/1000 [00:00<00:00, 200934.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "구두점 제거\n",
            "띄어쓰기 제거\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "띄어쓰기\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:12<00:00, 13.78it/s]\n",
            "  0%|          | 0/1000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "맞춤법교정\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [03:17<00:00,  5.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fudXVzcyWbFy",
        "outputId": "63d14c04-26e4-4c49-da80-97acaa49a5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spell_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['상담직원과 빠른 연결했음 좋겠어요',\n",
              " '안 기다리고 빨리 상담되었으면 좋겠다',\n",
              " '너무 오래 기다리고 상담이 늦어져요',\n",
              " '상담직원과 통화가 매우 힘들다',\n",
              " '상담받으려면 오래 기다리는 게 불편함',\n",
              " '상담하려면 많이 기다려야 하는 게 불편합니다',\n",
              " '상담원이 통화 중이라 많이 기다려야 해요',\n",
              " '상담직원과의 연결이 빠르게 연결되면 촣겠습니다',\n",
              " 'ars 상담직원 너무 많이 기다려야 하는 불편해요',\n",
              " '상담원 통화가 너 믜 힘듦',\n",
              " '상담원과의 연결이 빨리 되었으면 감사 힘니다',\n",
              " '상담원이 영결이 많이 힘이 듦',\n",
              " '5번 질문에 대한 답변은 상담직원 연결되기까지 기다리는 것 말곤 없는 듯',\n",
              " '상담을 하려면 좀 많이 기다려야 상담사분이 나오셔서 그게 좀 불편하네요',\n",
              " 'Talk 상담이 다시 생겼으면',\n",
              " '상담하려 하는 기다리는 시간 너무 길다',\n",
              " '상담직원과 빠른 속도로 연결이 되길 원합니다',\n",
              " '상담직원과 빠른 연결 부탁드립니다',\n",
              " '상담직원과 통화하기가 힘들다',\n",
              " '상담 한 번 받으려면 보통 5분 이상 대기해야 실질 상담은 2분 미만인데',\n",
              " '직원 상담 시간 너무 지연됨 짜증 유발',\n",
              " '상담 톡이 부족',\n",
              " '상담사와 연결 부분이 어려웠어요',\n",
              " '톡 상담 인원을 늘려 주세요 요즘 같은 때에는 전화상담보다 톡 상담이 더 신속하고 일 처리가 빠른 데 인원이 너무 적은 듯 매번 기다리다 일 처리 못하고 그냥 지나간 적이 한두 번이 아닙니다',\n",
              " 'ARS 지동 응답 불필요한 안내 축소 상담 직원과 빠른 연결을 원합니 다 추석 연휴 잘 보내세요',\n",
              " '1상담원과의 대화까지 소요되는 시간이 길어서 힘들었음 2 삼성카드사의 직원과 면대 면하여 질문 답변이 되길 수 있으면 좋겠습니다',\n",
              " '문자 상담이 나 온라인 상담이 가능한 부분이 많아졌으면 좋겠습니다',\n",
              " '상담직원과 연결이 좀 신속했으면 좋겠네요',\n",
              " '상담번호를 남겼는데 너무 늦게 주심이 너무 불만입니다',\n",
              " '상담직원 대기시간이 짫았으면 한다',\n",
              " '고객 입장에선 통화하기가 쉬웠으면 합니다',\n",
              " 'VIP 전용 상담원이 있었으면',\n",
              " 'ㅠㅠ 전화상담 좀 빠르게 되었으면 좋겠어요',\n",
              " '상당 직원 연결이 잘 안됨',\n",
              " '상담원 연결이 정말 힘들었다',\n",
              " '고객이 기다리지 않게 안내 직원 확대 부탁합니다',\n",
              " '상담원 연결이 어려워 요ㅠㅠ 10번 이상 시도해야 함',\n",
              " '주말에도 24시 상담사 연결 직접 되었으면',\n",
              " '골드 회원 전용 전화상담원 비치되어 있으면 좋겠어요',\n",
              " '주말에도 운영하였으면 합니다',\n",
              " '주말과 공휴일에도 이용 가능하면 좋겠다',\n",
              " '주말이나 공휴일에도 급한 업무를 처리할 수 있게 비상 상담원 배치 필요합니다',\n",
              " '실시간 채팅상담 만들어 주세요',\n",
              " '통화연결 대기시간이 길다',\n",
              " '상담원 전화연결이 될 때까지 대기시간이 많이 길다',\n",
              " '상담원 연결 대기시간이 짧아졌으면 좋겠어요',\n",
              " '상담원 연결까지 대기시간이 너무 길어요',\n",
              " '상담원과 연결되는 대기시간이 너무 길음',\n",
              " '상담원 연결 대기시간이 짧았으면 합니다',\n",
              " '통화연결 대기시간이 너무 길지 않았으면 합니다',\n",
              " '상담원 연결 대기시간이 길지 않으면 합니다',\n",
              " '상담원 통화대기 시간이 너무 길다',\n",
              " '상담원과 통화 하대기 시간이 너무 길어요',\n",
              " '상담원과의 통화대기 시간이 짧았으면 좋게 음',\n",
              " '상담원과의 통화대기 시간이 너무 길다',\n",
              " '상담원과의 통화대기 시간이 너무 길어요 ㅜㅜㅜ',\n",
              " '상담원과의 통화대기 시간이 너무 길다',\n",
              " '통화연결 시까지 시간이 너무 길다',\n",
              " '상담원 통화대기 시간이 짧았으면 합니다',\n",
              " '상담 연결 대기시간이 너무 길다',\n",
              " '전화 연결 대기시간',\n",
              " '전화 연결을 빠른 시간에 연결해 으면 합니다',\n",
              " '상담원 통화대기 시간이 오래 기다림',\n",
              " '대기시간이 너무 길다 통화만',\n",
              " '통화대기 시간이 너무 길다',\n",
              " '통화대기 시간이 너무 길어요',\n",
              " '통화대기 시간이 너무 길다',\n",
              " '통화대기 시간이 짧았으면 좋겠습니다',\n",
              " '통화가 너무 힘들어요 대기시간',\n",
              " '통화대기 시간 지체',\n",
              " '통화대기 시간을 줄였으면',\n",
              " '통화대기 시간 짤게 해주세요',\n",
              " '통화대기 시간이 너무 길어요',\n",
              " '통화대기 시간이 너무 오래 걸림',\n",
              " '통화대기 시간이 넘길다',\n",
              " '통화대기 시간이 매우 길다',\n",
              " '통화대기 시간이 너무 길다',\n",
              " '통화대기 시간이 너무 길어요',\n",
              " '통화대기 시간이 너무 길어요',\n",
              " '통화대기 시간이 너무 길었다',\n",
              " '통화대기 연결이 빨리 되었으면',\n",
              " '기다리는 시간 없이 상담원과 연결되었으면 합니다',\n",
              " '대기할 때 연결 시간ㅠ',\n",
              " '안내원 연결까지 대기시간이 너무 길어요',\n",
              " '연결 대기시간이 너무 길 음',\n",
              " '연결하는 대기시간 너무 길다',\n",
              " '상담원과의 통화대기 시간이 좀 길었다',\n",
              " '상담사와 통화대기 시간이 너무 길다',\n",
              " '상담사와 통화대기 시간이 너무 길어요',\n",
              " '상담원 연결 대기시간이 너무 길고 연결이 어렵습니다',\n",
              " '상담원과의 연결 시간이 너무 길고 통화하기가 너무 힘들어요',\n",
              " '대기시간 짧게 통화했으면 합니다',\n",
              " '빠른 시간 내에 상담원 연결을 했으면 좋겠습니다',\n",
              " '통화연결 시간이 길다',\n",
              " '대기시간이 길다 상담사와 통화가 힘들다',\n",
              " '통화대기 시간이 조금 많음',\n",
              " '다른 카드사의 경우 삼성카드사보다 통화대기 시간이 짧다',\n",
              " '전화 좀 빨리 연결됐으면 좋겠어요 기다리는 시간 너무 많아요',\n",
              " '상담원과의 연결 시간이 길었습니다',\n",
              " '상담원과 연결까지 시간이 많이 걸린다',\n",
              " '상담원과의 연결 시간이 너무 길다',\n",
              " '상담원 연결까지 시간이 너무 걸린다',\n",
              " '상담원 연결 시간이 너무 길고',\n",
              " '상담원 연결 시까지 시간이 너무 걸림',\n",
              " '전화 연결 시 대기시간이 길다',\n",
              " '타 카드사도 마찬가지지만 상담원과의 통화하기 전 기다리는 시간이 너무 길어요',\n",
              " '통화대기 시간이 너무 길다',\n",
              " '통화대기 시간이 길다',\n",
              " '통화대기 시간이 넘길다',\n",
              " '신한카드는 상담사 연결 시간은 짧아서 좋았습니다 반면 삼성카드는 넘기네요',\n",
              " '상담원 전화통화 대기시간이 짧았으면 함',\n",
              " '상담원과의 통화하려면 너무 오래 기다려야 하는데 좀 빨리 연결됐으면 좋겠어요',\n",
              " '상담사와의 통화대기 시간의 지연',\n",
              " '상담원의 통화를 원할 때 너무 시간이 많이 걸려요',\n",
              " '상담사와 빠른 시간에 통화되었으면 합니다',\n",
              " '통화대기 빨라 스먼 좋아요',\n",
              " '상담원 통화 연결이 빨리 되어 어 면합니다',\n",
              " '통화가 빨리 연결되기를',\n",
              " '어떤 때엔 상담사와 통화하기까지 대기시간이 길었어요',\n",
              " '상담사 연결까지 시간이 많이 걸리네요',\n",
              " '상담사까지 연결되는 시간이 너무 깁니다',\n",
              " '전화 연결이 어려울 때가 가끔 있어요 그래도 타사 카드보다는 연결이 잘 돼요',\n",
              " '상담원 통화가 빠르게 연결이 되었으면 좋겠습니다',\n",
              " '연결돼 김까지 가 시간이 너무 길다',\n",
              " '연결 시간과 다',\n",
              " '친절하면 좋겠음',\n",
              " '더욱 친절합시다',\n",
              " '좀 더 친절했으면 좋겠음',\n",
              " '친절하지 않다',\n",
              " '그다지 친절하지 않음',\n",
              " '좀 더 친절하여 쓰면',\n",
              " '친절하지 안 음',\n",
              " '조금 더 친절했으면 좋겠네요',\n",
              " '좀 더 친절했으면 좋겠다',\n",
              " '좀 더 친절했으면 좋겠음',\n",
              " '더 친절했으면 좋겠습니다',\n",
              " '친절하고 기다리지 않게 하여주기 바랍니다',\n",
              " '더욱 친절하셨으면 좋켔습니다',\n",
              " '친절도 매유 부족',\n",
              " '고객의 상담 필요시에 정확하고 친절한 상담 답변 부탁드립니다',\n",
              " '지금껏 상담받은 직원 중 최저네요',\n",
              " '친절한 상담 부탁드립니다',\n",
              " '친절하게 상담 부탁드립니다',\n",
              " '그저 상담은 복사 붙여넣기 시발놈들',\n",
              " '더 친절한 응대 원합니다',\n",
              " '전화 시 신속하고 빠르게 연결되었으면 좋겠습니다 또 상담원이 좀 더 친절했으면 합니다',\n",
              " '응대가 정확하지 않다 항상 몇 번 재차 물어야 힌ㅁ',\n",
              " '없음 좀 더 친절했으면 좋겠음',\n",
              " '고객이 잘못 들어 닷 질문하더라도 친절했으면 합니다',\n",
              " '친절한 설명 부탁드립니다',\n",
              " '친절하게 신속하게 처리가 됐으면 좋겠어요',\n",
              " '방금 상담받은 직원분 친절하지 않았습니다 좀 짜증이 느껴졌어요 ㅡㅡ',\n",
              " '고객 응대를 신속하게 하라',\n",
              " '정확한 안내와 신속한 처리 부족합니 다 직원들 역량 강화로 전문적이고 책임지는 상담을 부탁합니다',\n",
              " '상담이 매우 불편했습니다',\n",
              " '고객도 존댓말 하는데 상담원이 반말 투어로 상담함 굉장히 기분 나쁨 뭔 생각으로 저러는지 알 수 없음',\n",
              " '친절하게 부탁합니다',\n",
              " '고객의 입장에서 친절하게 설명 바랍니다',\n",
              " '다른 카드사 상담직원은 매우 친절한데 오늘 상담 직원은 최악의 상담사',\n",
              " '말투가 상투적이고 투박하신데 친절하게 응대해 주시면 좋겠습니다',\n",
              " '상담원 설명 천천히 정확하게 설명해주길 부탁합니다 감사합니다',\n",
              " '가끔 친절하지 안거나 빨리 끈으려 하거나 할 때',\n",
              " '친절하다는 느낌은 받지 못했음',\n",
              " '정확하게 설명이 필요하고 상담원 연결이 잘 안된다',\n",
              " '상담원분이 친절하셨으면 좋겠네요',\n",
              " '목소리에 친절함이 없다',\n",
              " '상담원이 스크립트 읽으며 고객 응대하는 것이 부자연스럽고 친절하다는 느낌이 없음',\n",
              " '상담직원 통화가 없는 것처럼 되잇어서 답답하고 말이 너무 느림',\n",
              " '상담에 의한 정확한 답변이 아니었습니다 공부 많이 하시고 상담받으십시오',\n",
              " '고객 중심의 상담이 되었으면 합니다',\n",
              " '상담원도 공부를 해야 할 듯합니다',\n",
              " '신속 정확해주세요',\n",
              " '상담 시간이 길고 직원들 교육 필요함',\n",
              " '너무 말을 질질 끌면서 말하고 친절함보다 답답하다',\n",
              " '이해하기 쉽게 설명해주시면 감사하겠습니다',\n",
              " '삼성카드 상담받기 전에 LG U 상담했었는데 밝고 내가 궁금한 것들을 친절하게 알려주셔서 상담한 내가 다기분이 좋았음 오늘 삼성 상담은 그냥 그랬음',\n",
              " '상담직원이 너무 불친절하여 기분이 나빴습니다',\n",
              " '문의 내용 신속 정확 처리 안내 상담원 안내 미흡에 대한 교육',\n",
              " '상담원이 내용을 모르고 답변',\n",
              " '짜증 없이 친절한 응대 부탁',\n",
              " '친절하고 적극적 대응성의 없게 영혼 없이 대답 No',\n",
              " '자세한 설명과 시간 좀 길게 대화하면서 설명을 해주셨으면 감사합니다',\n",
              " '상담 시에 고객의 의문사항을 충분히 들어주었으면 함 상담사 말소리가 너무 빨라서 불편함',\n",
              " '듣고 있는데 그것도 모르냐는 식의 답변이 돌아올 때 내가 알면 상담직원 하지 상담받고 있을까요ㅠㅠ',\n",
              " '일 똑바로 처리하세요',\n",
              " '상담원이 고객이 말하는 걸 이해를 못 하고 두 번씩 새롭게 말을 해야 알아들 음',\n",
              " '고객이 정확하게 모르고 있는 부분을 직원도 정확하게 몰라서 상담이 도움이 되지 않았다',\n",
              " '친절하다는 느낌을 받기 힘들 정도의 말투라서 상담 후 별로 기분이 좋지 않음',\n",
              " '좀 더 친절하고 자세하게 응대하길 바란다',\n",
              " '잘 했은데 친절이 좀 부족합니다',\n",
              " '다른 상담사에 비해 친절함 부족',\n",
              " '상냥하고 친절했으면 좋겠습니다',\n",
              " '더 자세히 설명 ㅎㅐ 주면 감사하겠음',\n",
              " '친절하지 못하다 말투가 딱딱해서 쉽게 물어보기 힘들다',\n",
              " '상담원이 내용을 잘 이해하지 못함 정확한 답변 못함 발음 부정확 못 알아듣겠음',\n",
              " '상담원 입장으로만 상담하지 마시길',\n",
              " '상담하시는 분들이 별로 친절하지가 않네요 좀 더 친절하게 응대 바랍니다',\n",
              " '상담원이 영혼 있는 ㅈ 답변을 원합니다 진정성 없는 답변은 기분이 나빴요',\n",
              " '고객의 입장에서 상담을 해주었으면 좋겠다',\n",
              " '상담원 응대 아주 불친절',\n",
              " '상담직원 불친절 말투 꽝',\n",
              " '카드 만들기가 힘들 엇 다 친절이 조금 고프다',\n",
              " '자세히 안내하고 이렇게 시간 끌지는 않습니다 대답도 애매모호하지 않고 정확하게 응대합니다',\n",
              " '상담사가 불친절한 느낌을 받았네요 상담이 귀찮다는 듯으로 받아들여져서 기분이 좋지만은 않네요',\n",
              " '쉽게 설명해주셨으면 합니다',\n",
              " '직원이 퉁명스러움',\n",
              " '5번 항 답변 내용 없음',\n",
              " '신속 정확이 필요합니다',\n",
              " '친절하고 배려해주는 느낌이었는데 방금 상담사 분운 아니네요',\n",
              " '상담직원 교육 필요',\n",
              " '고객에 입장에서 톤이나 상담을 해주셔야 한다고 생각됩니다',\n",
              " '상담원이 전문직 식이 없는 것 같아서 교육을 받고 상담에 임하길 바란다',\n",
              " '너무 로봇같이 딱딱하며 기분이 안 좋았음',\n",
              " '삼성카드 사 고객 응대가 매우 불친절함',\n",
              " '성의 없는 답변',\n",
              " '물어보면 답변을 못해',\n",
              " '오늘은 상담이 좀 답답한 응대였습니다',\n",
              " '말씀이 너무 빠르고 고객이 궁금해서 질문하는 도중 너무 말을 자르는 경향이 있습니다 불편했어요',\n",
              " '상담 질문에 대한 내용도 모르고 상담에 응함',\n",
              " '더욱 친절하게 대해 주세요',\n",
              " '상담ㅡ내용 빨라 처리되 엇음 합니다',\n",
              " '조금만 빨리 처리했으면 좋겠다 조금 친절',\n",
              " '코로나 19 때문에 힘들어하는데 조금 정확한 설명 필요함',\n",
              " '더욱더 발전한 신속한 상담 처리 기 대합니다 3',\n",
              " '오늘 상담 직원은 고객이 궁금한 사항을 바로 이해하지 못하고 같은 말을 반복하게 말하ㅁ 친절하는 것처럼 보이나 동문서답인 것 가타',\n",
              " '지금껏 상담사들 중 말투가 제일 기분 나빴 음',\n",
              " '답변할 때 확실하게 알고 답변해줬으면 좋겠어요 전에 다른 상담사와 상담할 때 좀 그랬거든요',\n",
              " '직원들에게 기초적인 발성법 교육을 시켜 표준어를 정확하게 발음하는 훈련을 시켰으면 합니다',\n",
              " '두 번이나 같은 내용으로 상담을 했지만 각각 다른 상담원 제대로 처리가 되지 않음',\n",
              " '직원이 귀찮은 듯 내용을 회피하고 해결 방법을 상담원이 아닌 판매점 사원과 상담해서 해결하라고 하니 참말로 답답하다',\n",
              " '상담원이 오늘 기분이 안 좋으신 가 굉장히 불친절하시더라고요',\n",
              " '고객 입장에서 잘 듣고 요점만 정확하게 답변했으면 좋겠습니다',\n",
              " '불친절하면 기분도 안 좋아해요',\n",
              " '투박하고 귀찮은 듯한 말투로 정말 상담하기 싫음',\n",
              " '늘 친절할 필요 없는데 벽이랑 대화하는 느낌이네요 이름 말할 때만 친절하시니 다 밖 상담사님',\n",
              " '언행을 좀 친절하게 대응했으면 좋겠습니다',\n",
              " '고객의 질문에 알기 쉽고 정확하게 설명해주셨으면 감사하겠습니다',\n",
              " '정확한 설명이 안 되어서 불편했다 상담원이 잘 모르는 것 같다 다시 다른 상담원과 통화 후 문제 해결을 도움받았다',\n",
              " 'OOO 상담원 본인의 선입견으로 고객 응대를 하여 큰 불편을 줌',\n",
              " '상담원이 가장 웃음 목소리를 내면서 상담받을 때 화가 났습니다',\n",
              " '4번 5번 내용은 나한텐 맞지 않고 상담사 연결이 어려워 힘듭니다 사람이 많아서 그렇겠지요 그래도 항상 친절한 상담에 감사드립니다',\n",
              " '좀 더 친절한 상담이 되길',\n",
              " '고객이 필요한 상담을 빠르고 정확한 처리를 해주신 감사하겠습니다',\n",
              " '친절하게 응 다 말투 등등 듣는 사람이 불편함',\n",
              " '상담직원이 질문의 이해도가 부족함',\n",
              " '5번 질문 난 해함 답할 내용이 없음',\n",
              " '상담하실 때 목소리 예쁘게 내려고 하기보단 발음을 정확하게 해주시는 게 좋을 것 같아요 친절하게 해주시는 것도 너무 좋지만 마스크 착용하시고 그런 것 때문이 발음 좀 정확하게 해주시면 통화하기가 더 좋을 것 같습니다',\n",
              " '고객이 필요한 것을 정확하게 알아듣기 쉽게 설명 부탁드립니다',\n",
              " '잘 모르니까 상담 통화를 한 건데 짜증 내는 말투 답답하다는 말투로 상담을 받으니 기분이 나빴습니다',\n",
              " '문의 내용에 대해 자세히 설명해주세요',\n",
              " '영혼 있는 상냥함을 원합니다',\n",
              " '고객 말은 안 듣고 상담사 말만 한 예를 들면 질문을 하고 답변을 받은 후 확인차 다시 되물으면 다시 설명함 고객이 확인차 되물었을 때 답과 상담사가 다시 설명한 답은 똑같음 결론은 고객이 잘 이해한 게 맞는데 상담사는 틀렸단 식으로 다시 설명함',\n",
              " '친절하다고 못 느낌',\n",
              " '안내사 항 설명하는 방법을 개선했으면 함',\n",
              " '자세한 설명이 매우 부족하다',\n",
              " '4번 5번 문항 답변 불편한 게 없었는데 체크하라고 강요합니다 상담원분들 더 우신데 고생하시니 다 좋은 하루 보내세요',\n",
              " '문의한 내용에 대한 정확한 답변 처리가 더 필요해 보입니다 고객의 말에 집중해서 상담해주셨으면 해요',\n",
              " '고객 응대 시 고객이 원하는 바를 정확히 파악하여 빠른 처리 응대해주시면 더욱 좋겠습니다',\n",
              " '다른 궁금한 분분까지 있는지 체크해 주시는 친절함이 없음',\n",
              " '형식적인 답변 대신 실질적인 빠른 업무처리를 기대합니다',\n",
              " '상담 내용에 맞게 적절한 대답이 해야 한다고 생각함',\n",
              " '홈쇼핑 심지어 지마켓 정도도 상담사가 목소리가 상냥하고 친절해서 상담하고 나면 기분이 좋습니다 그러나 삼성카드 상담사는 상담하고 나서 불쾌하고 기분이 매우 나빴습니다',\n",
              " '말투가 퉁명스럽고 친절한 말투가 아니라 기분상 ㅅ남',\n",
              " '조금만 친절히 답해주시면 감사하겠습니다',\n",
              " '고객의 말을 정확하게 인지하고 정확한 대답해주기를 바랍니다 고객이 상담원의 말을 이해 못 하는 것은 상담원의 응대가 미흡해서입니다 고객의 문의 내용이 한 가지 이상일 수 있으니 문의사항을 끝까지 듣고 대답해주세요',\n",
              " '상당원 친절도 형식적인 말투가 싫습니다',\n",
              " '상담원이 설명 권한을 더 높여 주 새요 그래야 정확히 대답하지요',\n",
              " '너무 사무적으로 응대',\n",
              " '상담할 때도 친절하지 않다는 느낌이었는데 상담 후 수고하세요라고 인사하는 데 상담사가 먼저 전화를 뚝 끊어버리시더라고 요 삼성카드뿐 아니라 다른 곳에서 상담했을 때도 이런 경우가 없었는데 참 당황스러웠습니다',\n",
              " '좀 더 친절한 말투로 얘기해주세요',\n",
              " '고객이 모르는 것에 대해서 물어보면 친절하게 응대해 주세요 말투가 무시한다는 느낌을 받았습니다 그리고 상담사 억양이 사투리인 거 같은데 통화 내내 거슬려고요',\n",
              " '타 카드사는 상담원들이 기계적인 것이 아닌 친절하게 응대함 삼성카드는 말도 빠르고 너무 기계 제인 응대만 함 고객의 요청사항을 잘 인지하지 못하는지 응대가 고객과 호응하는 감정이 부족함',\n",
              " '끝가지 고객 입장에서 상실하게 답변을 해주시길 바랍니다',\n",
              " '고객의 입장에서 모든 가능성을 열어놓고 최선의 방법을 찾아주는 적극적인 상담이 됐으면 좋겠다',\n",
              " '고객의 질문을 잘 이해했으면 좋겠다',\n",
              " '신속 정확한 답변을 원함 질문 내용 정확하게 파악하기',\n",
              " '상담직원 약간 부칠 전 직원 같아요',\n",
              " '좀 더 고객의 입장에서 응대해 주시길',\n",
              " '상담원톤이 좋지 아니하네요',\n",
              " '나이 많은 경 노인들께 좀 큰 목소리를 하고 알아먹기 좋은 말로 친절하게 대답해주어 서면 좋겠습니다',\n",
              " '고객 응대 수 말투가 상담 내내 거슬렸습니다 직원 교육 친절 응대에 절실하게 필요해 보입니다',\n",
              " '모르니까 물어보는 건데 모른다고 혼내는 기분이 들',\n",
              " '형식적인 답변 말고 상담자가 묻고자 하는 내용을 친절하게 잘 알려주십시오',\n",
              " '힘들지만 조금 더 친절하게 설명을 해주었으면 합니다',\n",
              " '자세하게 설명해주기',\n",
              " '좀 더 친절했으면',\n",
              " '4번 5번 질문해 당사랑 없는데요',\n",
              " '삼성카드 안내원이 제가 질문하는 내용에 대해 잘 모르시는 거 같습니다 정확한 답변 숙지 부탁드립니다 질문자 본인과 같이 질문 내용 답안 알았지 못하고 답변 아무렇게 하는 건 너무 성의가 없습니다 가끔씩 기본기 없는 상담원 전화응대는 답답함만 배가 시키니 다 모르면 다른 상담원에게 질문 넘겼으면 합니다',\n",
              " '문의하는 내용을 정확하게 인지하고 확실한 딥이 필요함',\n",
              " '좀 더 친절하게 대해주셨으면 해요 형식적인 느낌이 강했어요',\n",
              " 'KT 직원들과 상담했을 때의 불쾌감을 잊을 수가 없습니다 친철한 상담은 금세 잊히지만 따듯한 느낌은 오래가는 것 같습니다',\n",
              " '오늘은 불만투성이',\n",
              " '보험상담하면서 골절되면 500만 원 준다고 사기 침',\n",
              " '불만',\n",
              " '불만이 너무 많아요',\n",
              " '삼성은 이 나라의 축이 다 최선을 다해주길',\n",
              " '상담원의 기분에 따라 회사마다 거의 비슷 전에 오랜 기간이 명했다가 한동안 쉬었는데 다시 쓰게 되어 기대를 해본다 삼성에 불만이 없었는데 꼼수 안 부리는 회사이길 바란다',\n",
              " '시스템 문제 직원 문제는 없음',\n",
              " '너무 회사 위주이고 고객은 삼성동이다',\n",
              " '제발 전화 좀 그만',\n",
              " '다른 제 뉴 보험회사 전화 불미스럽습니다',\n",
              " '대출 관련 마케팅 문자 권유 불쾌함',\n",
              " '광고제 발놉',\n",
              " '쓸데없이 ㅡ 전화하지ㅡ 않았으면 좋겠습니다',\n",
              " '전화가 너무 많이 걸려옵니다',\n",
              " '문자나 메일로 상품 광고 안내를 했으면 좋을 듯 근무 중 상품 광고를 전화를 받으면 화가 남',\n",
              " '제휴 보험회사 연락이 안 왔으면 해요',\n",
              " '마케팅 활용 전화 시 미리 보험이면 보험이라고 얘기를 하고 통화 지속 여부 확인하고 통화했으면 좋겠습니다',\n",
              " '삼성카드는 그렇지 않겠지만 타 카드 회사는 보험회사와 연결되는 전화가 오는 경우가 많아서요 보험회사와의 연결은 없었으면 합니다',\n",
              " '연계된 제휴사 보험 안내 없는 카드사 돼주세요',\n",
              " '보험안내해서 해지했음',\n",
              " '좋았습니다 다만 보험 전화 좀 그만하셨으면 좋겠습니다 이미 가입한 보험이 있는데도 삼성카드로 연락 주 주 오고 있습니다 있다고 받았는데도 집요하게 연락 와서 힘들었습니다',\n",
              " '카드 취소되면 베네 포유 복지포인트 자동으로 복구시켜 주세요',\n",
              " '복지포인트 사용이 너무 어려워요',\n",
              " '한마디로 짜증 제대로 다시는 삼성 렌트 안 씁니다 여기도 담당 아니다 저기도 담당 아니다 정말 어디도 연락이 안 됨',\n",
              " '화면을 보고하는 게 익숙지 않아서 음성으로 하는 게 더 편합니다',\n",
              " '보이는 디지털 AS는 너무 불편하게 되어 있으며 원하는 화면이 보이지도 않습니다 첫 화면에 보이는 ars와 음성 ars를 바로 볼 수 있어야지요 ㅠㅠ',\n",
              " '모바일 화면 터치로 상담할 때 화면 화면으로 연결이 부자연스러워요',\n",
              " '스마트폰으로 상담하기가 너무 어려워요 보이는 ARS 음성 ARS 등',\n",
              " '스마트폰에 익숙하지 아니한 연령층의 간편하게 ARS 메인 화면에 바로 상담직원 연결',\n",
              " '화면 터치로 인해 상담원 연결이 더 어려워졌음',\n",
              " '보이는 ARS 화면이 너무 불편하고 시간이 지체되어 답답하다',\n",
              " 'ARS 이용 시 화면 터치 방식이 너무 힘듦',\n",
              " '화면 터치식에서 음성 ars로 돌아가는 버튼이 잘 찾아지지 않음',\n",
              " '연령대를 감안해서 화면 터치보다는 ars가 좋아요',\n",
              " '처음부터 화면 ARS로 접근되는 것이 아니라 음성과 보이는 ars를 선택할 수 있게 해 주심 좋을 것 같습니다',\n",
              " '1통화 연결 후 자동 음성으로 화면 터치 요구 시폰의 화면이 삼성 터치 화면으로의 전환이 안 되거나 수차례 시도 후 가능 2가족카드 관련 문의였으나 삼성 터치 화면엔 메뉴가 엊ㅅ었음',\n",
              " '초기 스마트폰 화면에 보이는 메뉴 구성이 이해가 어려워 상담 통화까지 어려워서 계속 잘못 터치하여 세 번째 통화만에 상담원 연결이 되었습니다 보이는 ARS가 좋긴 하지만 화면 메뉴 구성이 어렵게 되어 있는 것 같습니다',\n",
              " '상담원 통화 화면이 크게 나왔으면 좋겠음',\n",
              " '전화 이용 시 메인 화면에 디지털 화면 어렵습니다',\n",
              " '화면 터치식은 너무 복잡하다',\n",
              " '처음부터 바로 화면 상단을 터치하라는 음성이 나오는데 조금 불편하다',\n",
              " '해지 화면이 보이는 ars 등에도 있으면 좋을 듯',\n",
              " '전화하면 바로 보이는 ARS로 넘어가는 데 참 불편해 요 음성 보이는 화면 둘 중 번호로 선택할 수 있었으면 좋겠어요',\n",
              " '화면을 보고 터치하는 것도 편하지만 처음에 화면 터치를 할 것인지 음성 메시지를 듣고 할 것인지 구분할 수 있게 해주셨으면 좋겠습니다',\n",
              " 'ARS 시 화면 보면서 터치 방법을 알려줄 때 화면 터치 방식이 아닌 누르는 방식을 원할 시멘트가 끝날 때까지의 기다리는 시간이 너무 길다고 느낀다',\n",
              " '나이가 많은 사람들은 ARS 음성으로 바로 통화하기가 쉬운데 화면 보고 터치하는 게 쉽질 않습니다',\n",
              " '보이는 화면이 아니라 누르는 화면으로 상담하고 싶고 그게 더 전화상담하기까지 시간이 빠른 데 누르는 화면으로 서비스 받으려면 보이는 화면 터치해달라고 할 때 15초 이상 듣고만 있어야 누르는 화면으로 넘어가서 너무 불편',\n",
              " '보이는 화면을 통해 화면을 누를 때 다소 헷갈려요 글씨가 너무 많고 작아서 더 간결하면 좋을 것 같아요',\n",
              " '터치 화면 어려움',\n",
              " '보이는 ars 사용에서 음성 ars와 동일한 메뉴가 보이면 좋겠습니다',\n",
              " '화면 터치 불편해요',\n",
              " '안내 없이 터치 화면 안내원 연결하는 데 어려웠음',\n",
              " '처음에 화면을 보면서 상담 시 화면이 자꾸 움직이면서 무엇을 선택해서 문의해야 하는데 혼란스러웠다 이것은 반드시 개선해야 한다',\n",
              " '화면 터치 싫어요 선택할 수 있게 해주세요',\n",
              " '음성통화하기가 너무 불편해짐 화면 보고 눌러야 하고 누구를 위해서 이렇게 불편하게 만든 것임 화면 볼 거면 홈피 보지 누가 전화하겠음',\n",
              " '보이는 ars 무의미',\n",
              " 'ARS 화면 보고하는 서비스는 연결도 잘 안되고 너무 별로임 개선 필요',\n",
              " '스마트폰 터치보다 먼저 음성 ARS가 되면 좋겠습니다',\n",
              " '스마트폰 상단 터치해서 화면 나오는 방식 편하지 않습니다 불편해요',\n",
              " '보이는 ARS 서비스를 원하지 않는데 자동으로 화면이 전환되어 불편합니다',\n",
              " '문자로 화면 보고하는 서비스 에러 가납니 다 수고하십시오',\n",
              " '연결과 동시에 화면 터치로 이동되어 불편함 음성으로 선택 후 화면 선택으로 이동하게 하여 주셨으면 삽니다',\n",
              " '보면서 하는 ars를 바로 권유하지 않고 처음에 보이는 ars와 음성 ars 중에서 선택하게 해주세요',\n",
              " '처음 걸자마자 보이는 ars라고 터치하는 거 data만 소비되고 별로네요',\n",
              " '디지털 ARS 화면에서 상담원과 직접 통화 선택하기가 쉽지 않음',\n",
              " '보이는 대기화면에 상담원 연결 표시가 파란색이지만 쉽게 한눈에 찾기가 힘듦',\n",
              " 'Ars 연결 시 바로 연결 안 되고 화면으로 나와 오래 걸림 화면 또는 ars 선택 간단하게 좀 바뀌었으면 어르신들 화면 보기 어려움',\n",
              " '핸드폰 화면 터치 내용이 너무 많음',\n",
              " '보이는 ARS 말고 기존 ARS 연결하는 방식이 먼저 나왔으면 좋게 내요',\n",
              " '바로 보이는 ARS가 되었는데 나중에 보니 화면 아래쪽에 상담원 통화 버튼이 있더라고 요 안내 멘트에 상담원 통화 버튼도 보이는 화면에도 있다고 알려 주심 좋을 거 같네요 처음엔 안 보여서 전화를 여러 번 했다 끊었다 했고만요',\n",
              " '화면 터치가 자꾸 실수되는 문제',\n",
              " '화면 보기 서비스 안 하게 해주세요 화면 보기 상담 서비스를 중요합니다 멘트나 올 때까지 대기하는 것 불편해요',\n",
              " 'Ars 화면 이용이 서툴러서 헤맺음',\n",
              " '화면을 이용한 서비스에 바로 상담원 연결 화면이 있었으면 좋겠음',\n",
              " '보이는 에이 알 에스 멘트 계속 나오지 않았으면 해요 나중엔 음성으로 나왔지만 처음에 선택권이 있으면 좋겠죠',\n",
              " '화면으로 터치하는 ars는 불편함',\n",
              " '맨 처음 화면에 스마트폰을 보면서 누르기 하는 게 생각보다 어렵네요',\n",
              " '보이는 방법이 제대로 안됨업',\n",
              " '스마트로 전화하니 보이는 화면으로 넘어가는데 상담원 통화 메뉴를 찾지 못해 불편하였음',\n",
              " '보이는 화면이 매우 불편해서 3번째에 연결 제대로 됨',\n",
              " '화면 보면서 선택 불편',\n",
              " '모바일 화면을 보고 상담 요청할 때 어느 항목에 터치해야 할지 몰라 사용하기 불편함',\n",
              " '화면 터치로 넘어가는 게 너무 불편함',\n",
              " '보이는 것보다 상담이 더 편해요',\n",
              " '상담까지 번호 눌러야 되는 게 넘먾아요',\n",
              " '상담직원과의 통화가 너무 힘들고 복잡함',\n",
              " '상담원과 상담 전에 ARS 안내가 너무 길어서 불편합니다',\n",
              " '상담직원 연결되기 전까지 너무 많은 안내 멘트',\n",
              " '보앱으로 처리하려 먼 찾기가 너무 힘들다',\n",
              " 'ARS 상담 직원 바로 가 기해 당 상담직원 연결해주기 서비스가 있으면 좋겠네요',\n",
              " '상담 메뉴가 복잡하다',\n",
              " '상담직원과 연결하는 절차가 너무 복잡합니다',\n",
              " 'ARS 기계음은 짧게 바로 상담직원 연결로 수고하세요',\n",
              " '고객 전화에서 디지털에 취약한 고객들이 상담원 연결이 매우 불편하게 되어 있음',\n",
              " '보이는 상담은 원하는 내용 찾기 힘든 경우가 많은',\n",
              " '상담직원과 통화할 때까지 너무 복잡함 선택 메뉴 좀 편했으면',\n",
              " '디지털 상담 메뉴가 복잡해서 도움이 안 되는 것 같음',\n",
              " '보는 ars 상담은 불편함 상담원 전화가 편함',\n",
              " '상담원 전화 안내가 가장 빠른데 계속 보이는 ars로 안내하는 게 불편합니다',\n",
              " '상담한 ARS가 너무 복잡함',\n",
              " '상담직원 없이 터치하는 것 매우 불편',\n",
              " 'ARS 메뉴가 너무 많고 불필요한 안내 멘트가 길게 나온 다 빠르게 일 처리해야 되는 상황에선 여간 성가시다 형식적인 업무라 하지 말고 급히 처리해야 되는 고객 입장에서 생각하라',\n",
              " '홈페이지 정신없이 만들지 말고 광고 질 그만하고 직관적으로 만들어서 상담 없이도 문제가 해결되면 상담 통화량이 30 프로 줄어들 것으로 생각됨',\n",
              " '디지털 ars 설명이 다소 깁니 더',\n",
              " '디지털 상담 안내 시간을 기다리기 싫다 바로 누르는 ars 서비스로 가고 싶다',\n",
              " '음성으로 상담을 받고 싶은데 카톡 상담 참으로 넘어가는 시스템 매우 불편함',\n",
              " '챗봇 상담은 원하는 메뉴가 잘 없습니다',\n",
              " '정확한 홈페이지 안내가 부족함',\n",
              " '간단한 절차로 카드 앱을 사용하면 좋게 습니다',\n",
              " '5번 질문에 불만은 없고 ARS 연결 시 보이는 것이 불편함',\n",
              " '39살인 제가 디지털 카톡 연결되는 상담이 사실 불편하고 이게 뭐지 이 말이 먼저 나오네요 기존 방법으로 상담할 수 있게끔 해주세요',\n",
              " '곧바로 상담직원으로 넘어가는 단축키가 있었으면 합니다',\n",
              " 'ARS 연결이 너무 느려서 복잡하고 해서 연세가 많으싴 어르신들은 이용 못할 거 같음 친절한 상',\n",
              " '메인 메뉴 넘어가기 전에 디지털 ars 안내가 가장 짜증 남',\n",
              " 'ars 상담직원 통화 찾기가 어려움',\n",
              " '바로 보는 상담 ars 누르는 상담전화 상담사를 바로 고르게 해주세요',\n",
              " 'ARS 멘트 문의하는 대답을 잘 알아듣지 못해 여러 번 시도했다',\n",
              " '쳇봇 동문서 답 답변 너무너무 짜증 나요',\n",
              " 'ARS로 업무처리가 너무 번거롭다',\n",
              " '디지털 ars 인터페이스가 상담원 연결로 이어지기 어려운 것 같음',\n",
              " '디지털 상담 불편함 고전 클래식이나 음',\n",
              " 'ARS 이용 시 안내하는 내용이 너무 길어서 끝까지 듣는 것이 힘들다 상담원과의 통화하고 싶어서 하는 전화인데 다른 안내 말이 너무 많고 길어서 힘들어요',\n",
              " '디지털 안내 제한',\n",
              " '디지털 상담 없애라 너무 불편하다',\n",
              " '전화통화 시 상담원과의 통화가 되기까지 거치는 단계가 없이 연결되었으면 합니다',\n",
              " '상담사 연결은 제일 먼저 ㅇ번으로 하세요 몐트로 했으면 고맙겠습니다',\n",
              " 'ars 연결 시 상담원 바로 연결하기가 불편합니다',\n",
              " '상담원 연결까지 누르는 것도 많고 기다리는 것도 많았네요',\n",
              " '상담원 연결까지 안내가 너무 복잡합니다 디지털 서비스는 불편하고요',\n",
              " '상담원 연결이 바로 될 수 있도록 하면 참 좋을 거 같아 요 상담원과 통화 연결되기까지 너무 복잡합니다',\n",
              " '디지털 연결이 잘 안 됨',\n",
              " '연결이 번거롭다',\n",
              " '통화연결은 상담사랑 통화하고 싶기 때문에 전화를 한 건 데 디지털 ars 터치하라고 시간 끄는 게 불편하다',\n",
              " '누르고 대기하지 않고 상담사 연결이 바로 되어 통화로 문의하고 끝났으면 좋겠습니다',\n",
              " '통화까지 거치는 데가 많다',\n",
              " '그냥 바로 상담사로 연결되면 좋을 것 같아 요 상담사 연결하려고 20분 동안 헤맸어요',\n",
              " '최초 연결 시 aiars 연결 권유 없이 빨리 연결되면 좋겠어요',\n",
              " '상담원 연결 창도 바로 연결될 수 잇게 해주세요 디지털로 바로 돼서 불편합니다',\n",
              " 'Ars 연결하면 디지털로 넘어가 상담원 연결이 어려웠다',\n",
              " 'ARS 서비스 연결 시 제대로 연결이 안 되어 불편합니다 바로바로 상담원과 통화할 수 있게 손쉽게 연결이 되었으면 합니다',\n",
              " '통화대기 시간이 아닌 상담원과 통화하기 전의 진행 과정이 너무 길다',\n",
              " '전화 연결 시 디지털 ars 연결 외에도 상담원 연결을 바로 할 수 있었으면 좋겠습니다',\n",
              " '상담사와 연결하는 과정이 너무 시간이 걸립니다',\n",
              " '바로 상담원으로 연결이 안 되고 화면상으로 연결하는 게 어렵다',\n",
              " '상담원과 연결하기가 복잡합니 다 편리하게 상담원과 연결을 원합니다',\n",
              " '바로 통화 연결 기능이 없어 불편함',\n",
              " '디지털로 한 번 다시 통화 연결이 아니라 예전처럼 바로 통화 연결되었으면 좋겠습니다',\n",
              " '삼성카드 전화해서 디지털로 연결될 때 상담원 연결이 없어 5분 이상 헤매고 이것저것 다 눌러봐도 상담원 연결이 안돼 답답하네요',\n",
              " '나같이 메일이나 앱을 못하는 사람을 위해 비밀번호와 생년월일을 한 번만 입력해 놓으면 다음에는 비밀번호만 입력하면 안 될까 하고 충언 드립니다',\n",
              " '통화 초반 카드 한도에 대한 아기가 너무 길어요 ㅜㅜ',\n",
              " '기본 제공되는 카드 이용한도 안내를 중단해 주세요',\n",
              " '앱에서 내 카드 결제나 사용한도를 쉽게 알 수 있게끔 만들어 주세요',\n",
              " '카드론 대출받은 더 상환이 앱에선 안 돼 네오',\n",
              " '대출 상환도 앱에서 처리되도록 개선',\n",
              " '앱 카드 어플 이용이 어렵다',\n",
              " '삼성카드 앱 너무 복잡합니다 앱을 깔아도 실상 필요한 부분을 찾기가 어려워 전화하게 만드네요',\n",
              " '카드 이용내역 1년 넘은 부분을 앱에서도 확인할 수 있었으면 좋겠습니다',\n",
              " '장기 단기대출 상환을 앱에서 쉽게 할 수 있도록 보완해주세요 대출은 쉬운데 상환은 어렵게 해놓으셨어요',\n",
              " '삼성카드 앱이 많이 느려서 불편합니다',\n",
              " '문자를 보낸 내용에 출생연도 끝자리를 요일별로 처리한다는 내용을 추가해 주시면 좋을 것 같습니다 그래서 본인은 오늘 전화로 신청을 했다가 해당 요일이 아니라 신청을 못했습니다',\n",
              " '카드를 통한 통신료 전환 방법 및 call이 아니더라도 internet을 처리가 가능하도록 해주세요',\n",
              " '3명 자동이체 건인데 LG텔레콤 건은 바로 자동이체가 적부 되었다고 삼성카드에서 문자 온 더 SK텔레콤은 자동이체 신청을 먼저 했는데도 아직 문자가 안 오네요 결제 날짜는 넘었고요 SK 연락하니 자동이체 신청은 되었다고 하는데 상담사보다는 업무 쪽 문제인 거 같네요',\n",
              " '관리비 혜택이 없어 해지함',\n",
              " '아파트 관리비 납부자 번호 있으면 카드 납부 가능했으면 합니다',\n",
              " '한도 조정 맘대로 하지 마세요 사용자 동의를 얻어서 해야지 저 거들 맘대로 줄이고 지랄이야',\n",
              " '연회비가 저렴했으면 좋아요',\n",
              " '연회비를 저렴하게요',\n",
              " '삼성카드 연회비가 너무 바 쌉니다ㄷ',\n",
              " '연회비 없는 카드가 있으면 좋겠어요',\n",
              " '연회비 면제는 안 되나요',\n",
              " '연회비는 낮추고 사용을 많이 하게 하는 전략으로 하십시오',\n",
              " '연회비 면제 카드로 알고 사용했는데 연회비를 슬쩍 청구하네요 참나',\n",
              " '연회비 부담',\n",
              " '연회비가 부담된다',\n",
              " '연회비가 너무 부담돼요',\n",
              " '연회비가 부담스러워요',\n",
              " '연회비 부담',\n",
              " '연회비를 저렴하게 부탁드려요',\n",
              " '연회비가 없는 거는 없나요',\n",
              " '연회비가 너무 비싸다',\n",
              " '연회비가 비싸요',\n",
              " '연회비 너무 비싸요',\n",
              " '연회비가 너무 비쌈',\n",
              " '연회비가 너무 비싸',\n",
              " '연회비 너무 비싸다',\n",
              " '연회비 너무 비싸다',\n",
              " '연회비 비싸요',\n",
              " '연회비 업으면 좋게 어염',\n",
              " '연회비 많다',\n",
              " '연회비가 너무 비싸고요',\n",
              " '연회비가 비싸다',\n",
              " '연회비가 나에게는 비싸다',\n",
              " '연회비가 너무 많음',\n",
              " '연회비가 너무 비싸다 없음ㅇ',\n",
              " '연회비가 넘나비싸요',\n",
              " '연회비가 비싸다',\n",
              " '연회비가 비쌉니다',\n",
              " '연회비가 너무 비싸요',\n",
              " '연회비가 너무 비싸요',\n",
              " '연회비가 비싸다',\n",
              " '배송직원 매우 불친절 아주 많이',\n",
              " '카드 배송 부분에서 배송처리업체 불성실한 대응과 배송직원의 약속 불이행이 전반적으로 카드의 첫 부분인데 그 부분이 아쉽다',\n",
              " '2004년 SM 차를 구입하면서 삼성 캐피털에서 용자를 받았다 삼성 캐피털의 전화를 알아보는데 어려움이 있었다 르노 캐피털을 통해 삼성카드사로 합병되었다는 사실을 인지하는 데 2시간이나 걸렸다 근저당 설정 요건이 소멸되면 왜 본사에서는 해지를 하지 않을까 이 업무를 소비자의 몫으로 남겨놓는다는 것은 이해가 안 된다 핸드폰 전화번호를 입력하라는 데 16년 전 번호를 그대로 쓰는 사람이 얼마나 있을까 판매 시 서비스를 종료까지 해주길 바란다',\n",
              " '이벤트 기간 외에도 5개월 이상 무이자 할부 혜택 자주 많았으면 합니다',\n",
              " '무이자 할부 혜택 서비스를 제공해주시면 감사합니다',\n",
              " '무이자 할부 혜택이 왜 없나요',\n",
              " '무이자 사용 혜택을 기대합니다',\n",
              " '무이자 할부 자주 줬으면 좋겠다',\n",
              " '무이자 할부를 좀 더 많이 해주면 감사하겠습니다',\n",
              " '무이자 할부 많이 됐음 감사하겠습니다',\n",
              " '무이자 할부 기간을 더 늘렸으면',\n",
              " '연회비 부담스러워요 무이자 할부되는 곳 너무 제한적이어요 설사 삼성카드 무이자 할부가 할부가 되는데도 직원이 인지가 안 되어 있는 경우가 많아요',\n",
              " '무이자 할부 혜택을 좀 많이 줳으면 좋겠어요',\n",
              " '무이자 할부 이벤트 자 주 요망',\n",
              " '무이자 할부 혜택이 너무 부족하다고 생각합니다',\n",
              " '무이자 혜택을 받는 데가 많이 없다',\n",
              " '무이자에 대한 혜택 서비스 많이 제공했으면 좋겠습니다',\n",
              " '무이자 할부 혜택이 더 많았으면 좋겠습니다',\n",
              " '무이자 할부 혜택이 있었으면 합니다',\n",
              " '포인트를 좀 많이 주면 좋겠음',\n",
              " '포인트 적립되는 게 많았으면',\n",
              " '포인트 적립 많이 되게 해주세요',\n",
              " '포인트 적립이 더 높아지면',\n",
              " '카드 사용 시 포인트 적립이 적다고 생각됨',\n",
              " '많은 포인트 혜택을 주세요',\n",
              " '보이는 화면',\n",
              " '화면으로 보는 디지털 ARS',\n",
              " '화면 상담 서비스',\n",
              " '터치식 화면',\n",
              " '화면을 구현하는 ars',\n",
              " '화면 연결',\n",
              " '바로 보는 화면 서비스',\n",
              " '문자로 바로바로 답변이 오니 편리하고 좋아요',\n",
              " '화면으로 터치하니 너무 편하고 대기시간 짧아 너무 좋습니다',\n",
              " '상담직원 빨 통화할 수 있어서 감사합니다',\n",
              " '상담은 겔 바로 되어서 마우 만족',\n",
              " '휴일 상담 감사',\n",
              " '곧바로 상담사 염결',\n",
              " '오늘은 기분 좋게 빨리 응답해주어서 감사합니다 보통 때는 십분 정도 걸려으요',\n",
              " '상담 대기시간이 길지 않아 좋았습니다',\n",
              " '응답 속도가 신속하다는 것을 느끼곤 합니다',\n",
              " '오늘 같이 상담원 연결이 원활히 되어 좋았습니다',\n",
              " '연결이 빠르고 등급에 따라 주말에도 상담이 가능해서 만족',\n",
              " '주말 상담원 연결 서비스 너무 좋습니다',\n",
              " '골드 회원이라고 별거 아닌 건 알지만 괜히 기분 좋고 상담원 연결이 빠르게 돼서 좋습니다',\n",
              " '실시간 채팅상담 좋아요',\n",
              " '골드 회원이라 전화 연결을 빨리해주니 감사합니다',\n",
              " '채팅상담을 통한 처리가 편한 줄 몰랐고 사용해보니 좋았다',\n",
              " '24시간 콜센터 아주 만족합니다',\n",
              " '주말 근무 좋아요',\n",
              " '주말에 상담원 연결이 된다는 것이 다른 카드에는 없는 아주 편리하고 좋았습니다 덕분에 주말에 일 처리를 할 수 있었습니다 이 서비스로 인해 다른 카드사에는 더 큰 불평과 불만이 생기게 되었습니다',\n",
              " '주말임에도 불구하고 서비스를 받을 수 있다는 게 감동입니다 항상 감사합니다',\n",
              " '삼성카드 톡 상담이 24시간인 줄 몰랐는데 너무 편리하네요 답장도 빠르게 주셨고요 매우 만족했습니다',\n",
              " '골드 고객으로 지정되어 있어 빠른 안내 서비스를 받을 수 있어 좋았다 향후 오랜 고객에게 감동하는 서비를 제공해 주세요',\n",
              " '새벽에도 상담할 수 있어 좋았음',\n",
              " '삼성카드 플래티넘 데스크 상담은 최고라고 생각한 다 이유는 24시간이며 그것이 너무 좋다',\n",
              " '골드 회원 전용 상담제도',\n",
              " '오키드 전담 콜센터 이용이 편리합니다',\n",
              " '9시 이전인데도 톡 상담이 되어서 놀랐습니다',\n",
              " '주말 상담에 감사합니다',\n",
              " '삼성 더오 카드 프리미엄 전용 상담 센터에 매우 만족합니다 계속 운영 유지 부탁합니다',\n",
              " '골드 회원은 ars 빨리 연결',\n",
              " '골드 회원에 대한 상담 서비스 우대',\n",
              " '골드 회원 연결돼 만족',\n",
              " '골드 회원 빠른 상담사 연결감사합니다',\n",
              " '짧은 통화 연결 대기시간',\n",
              " '상담사 연결까지 대기시간이 짧아서 좋았습니다',\n",
              " '부가세 신고 시기에 맞게 바로 한 번에 연결 메뉴가 있어 너무 편했습니다 아이디어 낸 직원 꼭 포상해주세요 삼성카드 더 많이 애용하겠습니다 설문 5번 항목은 어쩔 수 없어서 1번 체크했습니다',\n",
              " '개인 정보 확인이 간편해서 좋았음',\n",
              " '친절상담과 상담원에 친절에 대단히 감사합니다',\n",
              " '친절한 상담 너무 감사합니다',\n",
              " '친절하게 상담해주셨어 감사합니다',\n",
              " '친절상담 감사하네요',\n",
              " '친절하게 상담해주시니 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '친절상담해주셔서 감사하네요',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절상담 감사합니다',\n",
              " '친절한 상담에 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절상담 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절상담 감사합니다',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사드립니다',\n",
              " '친절한 상담 감사했습니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절상담 감사합니다',\n",
              " '친절상담 감사',\n",
              " '친절하게 상담해주어 감사합니다',\n",
              " '친절한 상담 감사했습니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " 'OOO 님 친절하게 상담해 주셔서 감사합니다',\n",
              " '친절하게 상담 감사합니다',\n",
              " '친절한 상담에 감사합니다',\n",
              " '친절하게 상담해주어서 감사하다',\n",
              " '친절한 상담에 감사합니다',\n",
              " '친절하게 상담 잘 받고 감사합니다',\n",
              " '친절한 상담 감사드려요',\n",
              " '친절한 상담에 감사드립니다',\n",
              " 'OOO 님 친절상담 감사합니다',\n",
              " '친절한 상담 감사합니다ㅎㅎㅎ',\n",
              " '친절하게 상담 감사합니다',\n",
              " '친절하게 상담하여 주셔서 감사합니다ㅡ',\n",
              " '친절하게 상담을 해주네요ㅇ감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절상담 감사',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담해주셔서 감사합니다',\n",
              " '친절상담 감사',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사하였습니다',\n",
              " '친절상담 감사요',\n",
              " '친절하고 만족스러운 상담이 엇습니다 감사합니다',\n",
              " '친절하게 상담 감사드립니다',\n",
              " '친절하게 상담해 주셔 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사드려요',\n",
              " '상담 친절해주셔서 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절하게 상담해 주셔 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절상담 감사합니다',\n",
              " '친절상담 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절하게 상담에 응해주어 너무 감사했어요',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절한 상담 감사드려요',\n",
              " '친절상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절한 상담 감사',\n",
              " '친절한 상담 감사합니다',\n",
              " '눌 친절하고 상담에 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사드려요',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절한 상담 감사드려요',\n",
              " '다급했는데 친절한 상담 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절상담 감사합니다',\n",
              " '친절하고 배려심 있는 상담에 감사합니다',\n",
              " '친절하게 상담해주신 안내자에게 감사합니다',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절하게 상담해주어서 감사했습니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '상담 친절하게 받아주셔서 감사합니다',\n",
              " '친절한 상담 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사합니다 이 세 롬니',\n",
              " '친절상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절하게 잘 상담해주셔서 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절하게 상담을 해주어서 감사합니다',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '너무 친절상담해 주셔서 감사합니다',\n",
              " '상담 친절하시네요 감사합니다',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '친절하게 상담해줘서 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '언제나 친절 상담 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사했습니다',\n",
              " '친절하게 상담 감사',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담에 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사',\n",
              " '친절한 상담에 감사드립니다',\n",
              " '언제니 친절한 상담 감사합니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절상담 감사',\n",
              " '친절한 상담 감사하고요',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '바쁘신 시간대에 친절하게 상담해 주셔서 감사드립니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절하게 상담해주어서 감사합니다',\n",
              " '친절하게 상담해주셨어 감사했습니다',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절하게 상담해 주심 감사드립니다',\n",
              " '친절상담에 감사하다',\n",
              " '친절한 상담에 감사',\n",
              " '친절한 상담에 감사드려요',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절상담 감사드립니다',\n",
              " '상담사분 친절에 감사드립니다',\n",
              " '친절하게 상담해 주셔서 감사합니다',\n",
              " '친절한 상담 감사요',\n",
              " '친절한 상담 감사합니다',\n",
              " '친절하게 상담해주어 감사드립니다',\n",
              " '친절한 상담 감사',\n",
              " '친절하게 상담해주시니 감사합니다',\n",
              " '감사합니다 너무 친절했습니다',\n",
              " '친절 감사드립니다',\n",
              " '친절 감사용',\n",
              " '너무 친절했습니다 감사합니다',\n",
              " '친절합니다 감사합니다',\n",
              " '친절 감사',\n",
              " '친절 감사합니다',\n",
              " '친절해서 감사합니다',\n",
              " '친절하게 도와주셔서 감사합니다',\n",
              " '친절하게 해주셔서 감사합니다',\n",
              " '친절해서 감사',\n",
              " '친절에 감사합니다',\n",
              " '친절에 감사합니다',\n",
              " '친절하셔서 감사합니다',\n",
              " '매우 친절하여 감사합니다',\n",
              " '너무 친절하셔서 감사합니다',\n",
              " '친절하게 잘해주셔서 감사했습니다',\n",
              " '친절하게 잘해주셨습니다 감사합니다',\n",
              " '친절하고 감사합니다',\n",
              " '너무 감사합니다 친절하셨어요',\n",
              " '친절했습니다 감사합니다',\n",
              " '친절하게 해주셔 감사합니다',\n",
              " '친절 감사드려요',\n",
              " '친절하셔서 감사했습니다',\n",
              " '친절에 감사합니다',\n",
              " '친절하시고 빠르세요 감사합니다',\n",
              " '너무 친절해 주셔서 감사합니다',\n",
              " '친절하게 해주셔서 감사합니다',\n",
              " '너무 친절하셔서 감사합니다',\n",
              " '감사합니다 친절하셔서',\n",
              " '친절 감사',\n",
              " '친절 감사합니다',\n",
              " '친절합니다 감사합니다',\n",
              " '친절하셔서 감사드립니다',\n",
              " '친절에 감사드립니다',\n",
              " '친절에 감사합니다',\n",
              " '친절 감사합니다',\n",
              " '친절해주셔서 감사',\n",
              " '친절하세요 감사합니다',\n",
              " '친절 감사합니다',\n",
              " '친절함 예 감사드립니다',\n",
              " '친절하여 감사합니다',\n",
              " '친절하세요 감사합니다',\n",
              " '친절하시네요 감사합니다',\n",
              " '친절하게 답해줘서 감사합니다',\n",
              " '전체적으로 친절합니다 감사합니다',\n",
              " '친절하고 감사합니다',\n",
              " '친절 감사합니다',\n",
              " '너무 친절해서 감사합니다',\n",
              " 'OOO 님의 친절에 감사드립니다',\n",
              " '친절하시네요 감사합니다',\n",
              " '친절에 감사드립니다',\n",
              " '헝산 친절해서 감사합니다',\n",
              " '너무너무 친절 감사합니다',\n",
              " '친절하셔서 감사했습니다',\n",
              " '친절에 감사드립니다',\n",
              " '친절에 감사',\n",
              " '친절하시네요 감사합니다',\n",
              " '친절 감사합니다',\n",
              " '친절하시고 감사합니다',\n",
              " '너무 친절해서 정말 감사했습니다',\n",
              " '너무 친절하시니 다 감사합니다',\n",
              " '친절한 세서 감사합니다',\n",
              " '친절하게 해줘 감사합니다',\n",
              " '친절하고 감사했습니다',\n",
              " '친절하게 답해줘서 감사합니다',\n",
              " '친절하게 잘하고 계심 감사드립니다',\n",
              " '친절하게 감사합니다',\n",
              " '친절해서 감사합니다',\n",
              " '친절하시고 감사했습니다',\n",
              " '너무 친절하셨어요 너무 감사드립니다',\n",
              " '친절하게 되어주어 감사합니다',\n",
              " '친절하셨어요 감사합니다',\n",
              " '친절해서 감사요',\n",
              " '친절하게 해주셔 감사합니다',\n",
              " '매우 친절하셨습니다 감사합니다',\n",
              " '너무 친절해서 감사했어요',\n",
              " '늘 친절하셔서 감사합니다',\n",
              " '감사하고 친절하네요',\n",
              " '친절하세요 감사합니다',\n",
              " '친절해주셔 감사합니다',\n",
              " '친절이 죠 감사합니다',\n",
              " '친절하셔서 감사합니다',\n",
              " '친절하세요 감사합니다',\n",
              " '너무 친절해서 감사',\n",
              " '친절하게 해주셔서 감사합니다',\n",
              " '친절 감사',\n",
              " '친절이 감사한 것이 좋냈요',\n",
              " '친절하셔서 감사합니다',\n",
              " '친절하게 응해주셔 감사합니다',\n",
              " '친절하셔서 감사합니다',\n",
              " '친절 감사',\n",
              " '친절에 감사드립니다',\n",
              " '친절하시네요 감사합니다',\n",
              " '친절하여 감사합니다',\n",
              " '친절에 감사드립니다',\n",
              " '친절에 감사',\n",
              " '너무 친절해서 감사합니다',\n",
              " '친절하게 해 주 셨어 감사합니다',\n",
              " '친절하고 상냥하였습니다 감사합니다',\n",
              " '친절 감사합니다',\n",
              " '친절하고 감사합니다',\n",
              " '친절하게 대해주셔셔 감 사드립니다',\n",
              " '친절에 늘 감사하고 있습니다',\n",
              " '친절하게 해주셨어 감사합니다',\n",
              " '친절하게 잘 받았습니다ᅳ 감사합니다',\n",
              " '친절 감사합니다',\n",
              " '친절하고 속도감 있어 감사',\n",
              " '친절한 안냐 감사합니다',\n",
              " '친절하셔서 감사했습니다',\n",
              " '친절하게 다면 해주셔 너무 감사요',\n",
              " '정말 친절하셨습니다 감사합니다',\n",
              " '친절 감사합니다',\n",
              " '친절하셨습니다 감사합니다',\n",
              " '친절하여 감사했습니다',\n",
              " '친절하세요 감사합니다',\n",
              " 'OOO 님 너무 친절하게 알려주셔서 감사합니다',\n",
              " '친절해서 감사했어요',\n",
              " '친절하게 잘해주셔서 감사합니다',\n",
              " '친절해서 좋았어요 감사합니다',\n",
              " '친절하셔서 그저 감사합니다',\n",
              " '친절에 감사',\n",
              " '친절한 응 다 감사합니다',\n",
              " '친절에 감사합니다',\n",
              " '친절하시니 다 감사합니다',\n",
              " '친절하셨어요 감사합니다',\n",
              " '친절하고 감사했습니다',\n",
              " '친절 감사합니다',\n",
              " '친절해서 감사합니다',\n",
              " '친절하세요 감사합니다',\n",
              " '고맙고 친절했습니다 감사합니다',\n",
              " '친절하게 감사합니다',\n",
              " '타 카드사에 재산세 납부 문의를 했는데 답변을 잘해주었는데도 다시 상담사가 직접 전화까지 주면서 카드 사용 방법을 설명해주고 캐시까지 안내해 줌 상담사가 직접 전화까지 주는 경우는 없는데 고맙더군요',\n",
              " 'SKT 친절해요',\n",
              " '친절 상냥 Sk텔레콤이 아주 편하게 상담해 줍니다',\n",
              " '상담 감사합니다',\n",
              " '상담 감사합니다',\n",
              " '상담 감사했어요',\n",
              " '상담 감사합니다',\n",
              " '밤늦게까지 상담해 주셔서 감사합니다',\n",
              " '상담 감사합니다',\n",
              " '상담 감사',\n",
              " '상담 감사드립니다',\n",
              " '상담 감사요',\n",
              " '상담 감사합니다',\n",
              " '상담에 감사',\n",
              " '상담 너무 감사했습니다',\n",
              " '상담 감사해요',\n",
              " '상담 감사해요',\n",
              " '엘지유플러스 직원의 친절함 적극성',\n",
              " '상담해주신 직원분께 감사합니다',\n",
              " '상담직원분들 항상 감사드립니다',\n",
              " '응대 감사',\n",
              " '응대 감사했습니다',\n",
              " '오늘 상담 감사했습니다',\n",
              " '상담원님 감사합니다',\n",
              " 'Sk는 항상 친절해요',\n",
              " '하나카드 응대 시에는 매우 친절했어요 ㅜㅜ',\n",
              " '다른 카드사 직원은 친절하십니다',\n",
              " '다른 카드가 휠씬 친절해 씁니다',\n",
              " '한화손해 보 럼 상담원분들은 정말 차분하고 정확하게 아주 만족스러운 상담을 하심',\n",
              " '삼성전자 설치기사님들에 신속함에 감사합니다',\n",
              " '한화생명 너무 신속 친절',\n",
              " '다른 회사도 친절합니다',\n",
              " '다른 회사 직원들도 다 친절하게 받습니다',\n",
              " '타 회사 카드는 더 친절하다',\n",
              " '타사 카드 상담원은 다 친절했음',\n",
              " 'Sk텔레콤은 항상 친절하고 문의사항 더 있나 물어봐 줌',\n",
              " '감사하다고 할게 요 응대',\n",
              " '감사합니다 삼성카드 직원분',\n",
              " '감사합니다 좋은 하루 보내세요',\n",
              " '100세 시대에 나이 든 상담자의 문의를 친절하고 불편함이 없이 상담해주는 직원과의 통회는 너무 고맙게 생각되는 다른 곳의 상담 시 느꼈던 마음입니다',\n",
              " '구경만 하고 가려고 했는데 친절하게 너무 설명을 잘해주셔서 구매했습니다',\n",
              " 'Sk텔레콤이 제일 친절한 편인데 친절하기 갸막상막하엡니다',\n",
              " '궁금사항 너무 많아 시간이 걸렸음에도 끝까지 친절하게 자상하게 답해주신 일에 대해 감사함을 느낌 다른 회사',\n",
              " '오늘 통화한 114 고객센터 직원분인데 긴 질문에도 너무 상냥하고 친절하고 말투 속에 스마일을 하고 응대하는 모습을 느꼈습니다 끝까지 기분 좋게 통화하고 나의 기분까지 좋게 만들어주는 것 같아 행복감도 느꼈습니다',\n",
              " '유플러스 통신사는 매우 친절함 통화하고 나면 기분이 좋아집니다',\n",
              " '오늘도 좋은 하루요',\n",
              " 'kt 직원분 설명을 잘해주시고 프로모션 설명도 잘해주셔서 좋아요',\n",
              " 'SK텔레콤 회사 직원들이 전화응대를 잘 합니다',\n",
              " '정확하세요',\n",
              " 'Sk텔레콤에서 쉬운 말 설명과 그리고 신속한 연결과 상담 내용 문자로 설명 좋았어요',\n",
              " '타 회사에 불편 접수를 했는데 상담분이 엄청 미안해하시고 신속하게 처리 도와줘서 감동받음 친절하게 대응해주고 건강도 염려해주는 멘트가 두고두고 기억되네요',\n",
              " 'Skt 통신사 콜센터 상담직원은 신속하고 부족한 부분은 확인해서 다시 알려줌 미안할 정도 친절함',\n",
              " 'BC카드 상담원이 상담이 꿑났는 대다수 전화가 와서 자세한 상담을 해주었다',\n",
              " 'SKT 전화상담 끝나고 나면 항상 문자가 날라오는데 상담했었던 내용에 대한 부분과 상담 요청자가 이야기했던 내용을 담아 친절하게 보내주는 문자가 엄청 감동적이었음',\n",
              " '신속함',\n",
              " 'Sk텔레콤 고객센터 친절하기도 하지만 내가 궁금한 것들도 궁금하지 아니한 것들도 궁금하게 만들게끔 하는 설명도 매우 만족스럽습니다',\n",
              " 'KB카드사는 문의 내용에 대해 친절히 듣고 하는 말에 대해 다 경청 후 안내를 해서 기분 좋은 통화를 했었어요',\n",
              " '타 회사는 신속하게 처리됩니다',\n",
              " '롯데는 참 친절 하드만요',\n",
              " '롯데카드사는 친절하게도 방법을 알켜줍니다',\n",
              " 'Gs 상담은 정말 빠르게 처리 잘해주시고 다른 곳보다 신속 정확해서 ㅇ 실음이 가요',\n",
              " '최근 삼성생명 상담 업무로 전화 이용 시 굉장히 편안하고 친절한 응대 서비스가 인상적이었습니다 물론 직원들마다 편차는 인정합니다만 짧은 시간 전달되는 상담원의 응대가 고객의 마음을 움직일 수 있다는 걸 기억해주시길 바랍니다',\n",
              " '신한카드사 직원분들은 친절하고 미리 예상해서 말씀해 주셔서 대화가 편하고 좋습니다',\n",
              " 'LG 고객센터 상담 여직원은 고객 문의가 잘 해결될 때까지 끝까지 확인 전화해서 상담했던 게 기억에 남는다',\n",
              " 'SKT 상담원들 짱',\n",
              " '신한은행의 상담사에게 모바일 통한 추가 계좌 계설을 문의한 적이 있었는데 정말 친절하게 너무 성심성의껏 상담해주셔서 감동한 적이 있었다 전화 한 통화로 신한은행사의 좋은 기억만 계속 남게 된 사례',\n",
              " '하나카드 상담사 간결하고 친절하게 필요한 것만 구체적으로 설명해주어 이해하기 쉬웠음',\n",
              " '신속',\n",
              " 'T 고객센터 상담원분들 상당히 친절합니다',\n",
              " '우체국 콜센터 직원은 전화하니 고객 요구 사항을 빨리 파악하고 고객 입장에서 처리함',\n",
              " 'Sk Telecom의 친절과 전문성',\n",
              " '다른 카드사에서는 조금 더 적극적으로 친절하게 상담',\n",
              " '타 회사 경험인데 해당 사건이 해결되고 나서 잘 해결되었는지 상담했던 분이 전화 주셔서 너무 좋았다',\n",
              " '위에 내용이 롯데 상담사들이 친절하게 진행하는 방법 아다',\n",
              " 'OOO 상담원님 코로나 감염 조심하세요',\n",
              " 'Sk텔레콤 상담직원들 요 예전 경험인 대요 진심으로 대화하는 느낌이 확실히 좋았던 기억이 있습니다',\n",
              " '제가 홈쇼핑 상담원과 통화할 때 그 상담원은 다른 상담원에게 넘겨도 될 법한 일도 본인 교육 때문에 자리를 비우게 되는 것까지 얘기해주며 상담에 최선을 다하는 모습에 큰 고마움을 느낀 적이 있습니다 그 직원이 엄청나게 친절한 말투는 아니었지만 고객을 대하는 마음이 느껴질 때 고객도 감동을 받는 것 같습니다 가끔 목소리만 하이톤으로 하면 친절하는 줄 아는 상담사분들이 계셔서 말씀드립니다',\n",
              " '삼성전자 부장님 친절하게 설명해주셔서 감사드립니다 김치냉장고 구입하였습니다',\n",
              " '황상 수고하시는 상담직원분들에게 감사하다는 말씀드리고 싶네요',\n",
              " '타 회사에서는 친근하게 답변 주셔서 상담도 편하게 느껴지고 상담 끝나고도 좋았던 것 같습니다',\n",
              " '현대카드 친절하더라고요',\n",
              " '회사 말씀은 드리지 않겠지만 중소 회사지만 너무 친절하고 너무 쉽게 답변해주어 끝에 복 많이 받으시라는 이야기를 해준 적 있습니다',\n",
              " '타사 카드 상담원님 친절함에 놀랐습니다',\n",
              " '메리츠는 굉장히 친절합니다 고객을 소중히 여기는 듯',\n",
              " '타 카드사에서도 똑같은 상담을 받아봤었고 사용도 했었었는데 진심으로 고객의 입장을 들어주고 도와주려고 하고 친절하게 대하는 모습이 참 좋았었다',\n",
              " '신한카드 상담 서비스가 더 친절하고 고객의 애로사항을 해결하고자 노력합니다',\n",
              " 'SKT 상담 직원의 소비자 편에서 따져봐서 소비자에게 맞는 월 정액 추천 아주고 메웠다',\n",
              " 'KT는 상담사 응답이나 확인도 가 빠르고 정확했어요 참고하세요',\n",
              " '글쎄요 sk telecom도 많이 친절함',\n",
              " 'Sk 통신사 상담뭔의 태도가 신속 친절해서 칭찬할 만하다',\n",
              " '롯데카드 상담사님은 같은 질문에도 성의 있게 답변해주시고 친절히 설명을 잘해주셔서 삼성과 롯데 둘 중 카드 하나면 쓰라면 롯데만 쓰고 싶네요',\n",
              " '국민카드 사 상담 서비스 경험인데 요 고객이 처리하고자 하는 내용을 정확히 모르니까 상세하게 알아서 다시 전화가 와 말해줬을 때 감동받았습니다',\n",
              " '전체적인 불편함과 불만은 없었습니다 상기 문항의 불편함도 없을 정도로 좋았습니다',\n",
              " '다른 회사 상담사분께 잘 몰라서 불안한 마음으로 문의했는데 내가 문의한 것에 대해 좋은 정보를 이야기해 주어서 마음도 기쁘고 안심이 되었습니다',\n",
              " 'LG 상당히 친절하고 공감하고 상냥하고 도와주려 성의를 보임',\n",
              " '하나은행은 친절히 잘 설명해줌',\n",
              " '롯데카드 상담 시 바로바로 문제를 해결해주고 답변도 여러 가지 방법으로 알려준다',\n",
              " '애플이 상담 서비스 ㅆㅅㅌㅊ 임 전문성도 뛰어나고 여유롭고 친절하고 배려함 고급 호텔 식당에서 서빙 받는 느낌과 비슷함',\n",
              " '좋은 하루 보내세요',\n",
              " '타 회사 하나은행의 경우가 있으나 기재하긴 너무 기네요 지금도 기억나는 최고의 친절 직원이어서 기억이 많이 남네요',\n",
              " '다른 카드사는 부드럽고 친절하게 연체 미납 카드비를 설명해줘서 무한 감사를 했다 아주 친절하게',\n",
              " '감사하게 생각합니다',\n",
              " '국민카드 발급 상담 시연회비 및 기타 사항들을 꼼꼼한 비교 설명으로 카드 발급 선택을 맞춤형 카드로 발급받을 수 있게 친절했었던 상담원이 지금 생각해도 감사하네요',\n",
              " 'SKT가 상담할 때 더 상냥하게 느껴져 요 목소리에서도 미소가 느껴져요',\n",
              " '타 회사 전화상담 시에 알아들을 수 있을 때까지 설명해줌으로 해서 너무 고마움을 느낄 때가 있었습니다',\n",
              " '신한카드가 좀 더 친절함',\n",
              " '국민카드 친절하고 서비스 최고입니다 삼성카드도 못지않고요',\n",
              " '역시 삼성 감사합니다',\n",
              " '힘든 시국에 상담원분들 고생해서 안쓰럽다',\n",
              " '예컨대 SK Telecom의 상담직원들 응대 태도 처리 방식 등 직접 체험하여 좋은 점을 그대로 좀 배워 실행 Su rprise 하게 해주시기 바랍니다',\n",
              " 'Skt에서 전화받으신 분이 잘 모르는 부분을 질문했어요 보통 담당하는 다른 부서로 넘기거나 할 텐데 본인이 직접 몇 시간 안에 그건을 파악하고 공부를 해서 연락을 주시고 직접 안내를 해주시더라고 요 상담자분이 뿌듯하게 안내해 주시는 자신감 넘치는 안내를 들으며 저도 괜스레 기분이 좋았었네요 그만큼 회사에서 직원분을 위해 공부를 할 시간과 배려를 해줬으니 가능한 일이라 생각합니다',\n",
              " 'SK텔레콤도 노인 배려로 차분하고 이해 돕기에 최선을 다하고 있어요',\n",
              " '고객이야기의 공감 다이슨 고객센터',\n",
              " '신한이 훨씬 친절하네요 삼성을 주로 이용했었는데 괜히 그랬나 싶어요',\n",
              " '삼성증권에서 받은 서비스 요청하지 않았지만 저의 조건에 맞는 설명과 사실을 따로 알아보시고 전화 주셔서 알려주는 적극적인 응대',\n",
              " '다른 카드 상담원은 고객이 뭘 원하는지 미리 응답해줌',\n",
              " '고마워요',\n",
              " '고마워요',\n",
              " '고마워 요항 시 친',\n",
              " '최선을 다하시고 몸 건강하세요',\n",
              " '신한카드의 OOO 직원의 경우 야간 분실신고 상담 시간이었음에도 신속하고 책임감 있게 본인의 일처럼 상담하고 일 처리해줌',\n",
              " '잘하고 있어 다른 불편사항은 없습니다',\n",
              " '신한카드 사상담 시스템이 맘에 듭니다',\n",
              " '통신 3사 국민건강보험 등 회사가 상담을 친절 신속히 잘 함 한 번 비교해 보세요',\n",
              " '국민카드는 혜택 사항을 매달 알려주고 빠르게 처리해줘서 항상 감사하게 쓰고 있습니다',\n",
              " '삼성 팬입니다 현제 만족합니다',\n",
              " '00카드는 상담하면 기분이나 뻐집니 다 ㅋ 삼성은 좋아요',\n",
              " '삼성카드 상담 불편사항이 없음',\n",
              " '삼성카드가 제일 전문적이고 정확하다',\n",
              " '1등 기업인 만큼 우수하다 생각함',\n",
              " '상담한 직원분이 끝까지 책임지고 해결해주시는 부분은 타 카드사에서는 보기 힘든데 삼성카드는 그렇지가 않네요',\n",
              " '가장 좋은 카드회사입니다',\n",
              " '역시 삼성입니다',\n",
              " '역시 삼성 맴입니다',\n",
              " '역시 삼성은 이 나라 제일 기업입니다 감사하고 긍지를 느낍니다',\n",
              " '다른 카드사보다 더 업무가 편리해서 좋아요',\n",
              " '다른 카드사보다 좋아요',\n",
              " '어느 카드사보다 빨라서 좋아요 그냥 굿',\n",
              " '늘 만족하며 사용하고 있습니다 감사합니다',\n",
              " '만족합니다 사용함에',\n",
              " '아주 싼 저리의 상품 있다고 안내받는 전화받았을 때 매우 도움 되었습니다 감사합니다',\n",
              " '어려울 때 대출해 주셔서 큰 힘이 됩니다 감사합니다 삼성 사랑합니다',\n",
              " '삼성카드사에서 보안을 위해 제 카드를 모니터링해주고 있는지는 몰랐습니다 보이스피싱 당한 줄 알았는데 상담원과 통화를 하고 안심할 수 있었습니다 너무 감사합니다',\n",
              " '가장 최고로 좋은 점은 빠른 음성통화 연결 폰 화면에 터치 화면이 같이 뜨는 것이 타사에 비해 압도적인 편리함',\n",
              " '통화 시 같이 연결되는 화면 서비스가 상당히 편하고 좋다',\n",
              " '화면으로 볼 수 있어 너무 좋아요',\n",
              " '화면을 터치하며 상담하는 점',\n",
              " '디지털 ars 보이는 서비스 좋아요',\n",
              " '문자서비스 편리하고 좋습니다',\n",
              " '한도 올려주셔서 감사해요 잘 쓰고 잘 갚을 게요',\n",
              " '한도 상향 잘 올려 주셔서 감사',\n",
              " '삼성카드 사용을 별로 하지 않아서 연회비가 부담스러워 해지할까 했는데 미리 알아서 연회비 면제 서비스를 해줘서 기분이 좋았습니다',\n",
              " '카드 분실된 지 1분 만에 카드를 통해서 연락받아 바로 찾았어요 잃어버린 지도 몰랐는데 감사합니다',\n",
              " '수시로 6개월 무이자 할부와 링크 혜택이 다른 카드와 구별되는 기능이 편리함',\n",
              " '무이자 할부 자주 많이 주셔서 감사합니다',\n",
              " '무이자 혜택 만족 긴 할부 만족 잘 쓰고 있습니다',\n",
              " '무이자 혜택이 많아 잘 쓰고 있어요']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB6bcQlNRRP-"
      },
      "source": [
        "# 우선순위로 분류 # 1부터 44까지의 수로 분류 # 0은 없음\n",
        "for i in range(len(classification)):\n",
        "  data.loc[(data['최종분류(우선순위 가장 높은것 선택)'] == classification.loc[i,'의도명(유형)']), '최종분류(우선순위 가장 높은것 선택)'] = i+1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReE7AEo7SIbR"
      },
      "source": [
        "data_list = []\n",
        "for q, label in zip(spell_data, data['최종분류(우선순위 가장 높은것 선택)'])  :\n",
        "    dataf = []\n",
        "    dataf.append(q)\n",
        "    dataf.append(str(label))\n",
        "\n",
        "    data_list.append(dataf)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71kzLOZfS4b3",
        "outputId": "fa066e2f-4ad5-4717-84bb-d16d333527ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#train & test 데이터로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)\n",
        "\n",
        "print(len(dataset_train))\n",
        "print(len(dataset_test))                             "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "750\n",
            "250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3R5krDhS7_E"
      },
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljJVhJVKTYbt"
      },
      "source": [
        "# Setting parameters\n",
        "max_len = 1000\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuVdxP0KVf22"
      },
      "source": [
        "batch_size = 1\n",
        "num_epochs = 10\n",
        "learning_rate =  0.01"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc3DMxPcTck2",
        "outputId": "1dd66890-6adb-4064-bddb-adff4b8b6efe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#토큰화\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GLg75SdTrvi"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=2)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8THTBhS4T0eU"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=44,   ##클래스 수 조정##\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7pAjYDVJY8",
        "outputId": "e66fcd1d-1f14-46e9-c85f-4e3c82a51972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#BERT 모델 불러오기\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "\n",
        "#optimizer와 schedule 설정\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "#정확도 측정을 위한 함수 정의\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "    \n",
        "train_dataloader"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f2f74352610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7BBOfROVMD-",
        "outputId": "98986f45-cba0-49df-9a95-bd82c55b7d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475,
          "referenced_widgets": [
            "7a52a5f1de034504ae71cd70fee438c0",
            "b1033d9ebb9c4c72888305701694a818",
            "dbade7ee2d7a49c294260212263a0f65",
            "464bffeca49644c9a8f1a5216842eeac",
            "e615b235a74d454890d6c7d28d16cdf7",
            "04f15c834ee94665bc04beefb830505e",
            "c33c2a980eff4927ba1f74c6867b6817",
            "e6b0fc725ac04ec18fda27e2c852440f"
          ]
        }
      },
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    \n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a52a5f1de034504ae71cd70fee438c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=750.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-480b6a139979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-048a6b8713a9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         )\n\u001b[1;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 )\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    369\u001b[0m     ):\n\u001b[1;32m    370\u001b[0m         self_attention_outputs = self.attention(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    313\u001b[0m     ):\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     ):\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyOQGE4pVQ33"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}